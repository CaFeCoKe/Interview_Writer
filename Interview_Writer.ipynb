{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1QW2zOiyfny1GENml9lfq8sG-qhO1TIrH","authorship_tag":"ABX9TyNZ2RJa0RpyXIL8RrzpKW39"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 사전 준비"],"metadata":{"id":"CINkJXuBvbfu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"w3MoHKy-va8H"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"markdown","source":["# 데이터 불러오기"],"metadata":{"id":"V3HtXnIzwHer"}},{"cell_type":"code","source":["import pandas as pd\n","\n","interview_data = pd.read_csv(\"/content/drive/Othercomputers/내 컴퓨터/Interview_Writer/Interview_Data.csv\")"],"metadata":{"id":"aJopDsrdwHGu","executionInfo":{"status":"ok","timestamp":1685339055361,"user_tz":-540,"elapsed":1262,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["interview_data.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"NmUs79nUyaVb","executionInfo":{"status":"ok","timestamp":1685339055361,"user_tz":-540,"elapsed":9,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"0c4b0a64-e8d7-4224-95bc-782c9f516cbf"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          Question  \\\n","0             특별히 회사를 선택한 이유와 입사 후 포부에 대해 기술해주십시오.   \n","1  지원직무를 선택한 이유와 해당직무에 본인이 적임자라고 생각하는 이유를 기술해주십시오.   \n","2             본인이 다니고 싶은 회사와 동료들은 어떤 모습인지 기술해주십시오.   \n","\n","                                              Answer  \n","0  대학교 1학년 2학기, 컴퓨터 프로그래밍 및 실습수업을 통해 프로그래밍에 관심을 가...  \n","1  대학교 2학년 1학기, 프로그래밍언어 수업을 통해 영상처리를 처음 접하게 되었습니다...  \n","2  제가 다니고 싶은 회사는 개인 역량을 강화하는데 도움을 주는 회사입니다. 회사에 취...  "],"text/html":["\n","  <div id=\"df-4a288fab-3dcf-4bf6-91e5-21561393fc0f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Question</th>\n","      <th>Answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>특별히 회사를 선택한 이유와 입사 후 포부에 대해 기술해주십시오.</td>\n","      <td>대학교 1학년 2학기, 컴퓨터 프로그래밍 및 실습수업을 통해 프로그래밍에 관심을 가...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>지원직무를 선택한 이유와 해당직무에 본인이 적임자라고 생각하는 이유를 기술해주십시오.</td>\n","      <td>대학교 2학년 1학기, 프로그래밍언어 수업을 통해 영상처리를 처음 접하게 되었습니다...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>본인이 다니고 싶은 회사와 동료들은 어떤 모습인지 기술해주십시오.</td>\n","      <td>제가 다니고 싶은 회사는 개인 역량을 강화하는데 도움을 주는 회사입니다. 회사에 취...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a288fab-3dcf-4bf6-91e5-21561393fc0f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4a288fab-3dcf-4bf6-91e5-21561393fc0f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4a288fab-3dcf-4bf6-91e5-21561393fc0f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["interview_data.tail(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"v4uJE8dnybz_","executionInfo":{"status":"ok","timestamp":1685339055362,"user_tz":-540,"elapsed":8,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"d6d1b1c2-29a3-4f18-c3f8-2bc7d102c919"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              Question  \\\n","117  개발을 하면서 겪었던 기술적인 문제를 서술하고, 그 과정에서 겪었던 시행착오와 그에...   \n","118                           입사 후 이루고 싶은 최종목표는 무엇입니까?   \n","119  성격의 장점과 단점을 기술해 주시기 바랍니다. 입사 후 장점은 어떻게 활용하고 단점...   \n","\n","                                                Answer  \n","117  프로그래머는 `조금 더 편리한 방법은 없을까?` 궁금하지 않다면 더 이상의 발전은 ...  \n","118  입사 후, 기존에 있던 업무 매뉴얼과 문서들을 바탕으로 업무에 빠르게 적응하겠습니다...  \n","119  함께 완성한 것이 혼자 완성한 것보다 결과 그 이상의 가치를 가집니다. 혼자 완성하...  "],"text/html":["\n","  <div id=\"df-a9f156cf-0614-4165-ac0d-947123bc4827\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Question</th>\n","      <th>Answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>117</th>\n","      <td>개발을 하면서 겪었던 기술적인 문제를 서술하고, 그 과정에서 겪었던 시행착오와 그에...</td>\n","      <td>프로그래머는 `조금 더 편리한 방법은 없을까?` 궁금하지 않다면 더 이상의 발전은 ...</td>\n","    </tr>\n","    <tr>\n","      <th>118</th>\n","      <td>입사 후 이루고 싶은 최종목표는 무엇입니까?</td>\n","      <td>입사 후, 기존에 있던 업무 매뉴얼과 문서들을 바탕으로 업무에 빠르게 적응하겠습니다...</td>\n","    </tr>\n","    <tr>\n","      <th>119</th>\n","      <td>성격의 장점과 단점을 기술해 주시기 바랍니다. 입사 후 장점은 어떻게 활용하고 단점...</td>\n","      <td>함께 완성한 것이 혼자 완성한 것보다 결과 그 이상의 가치를 가집니다. 혼자 완성하...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9f156cf-0614-4165-ac0d-947123bc4827')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a9f156cf-0614-4165-ac0d-947123bc4827 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a9f156cf-0614-4165-ac0d-947123bc4827');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["# 텍스트 전처리"],"metadata":{"id":"vU9HlfgHzILG"}},{"cell_type":"code","source":["!pip install soynlp"],"metadata":{"id":"S2Do0aTuDX52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 회사이름 리스트를 정규표현식으로 변경\n","file_path = '/content/drive/Othercomputers/내 컴퓨터/Interview_Writer/companies_name.txt'\n","\n","with open(file_path) as f:\n","    names_list = f.read().splitlines()\n","\n","for i in range(0, len(names_list)):\n","    if i == 0:\n","        names_list[i] = str('(' + names_list[i])\n","    elif i == (len(names_list)-1):\n","        names_list[i] = str('|' + names_list[i] + ')')\n","    else:\n","        names_list[i] = str('|' + names_list[i])\n","\n","names_str = ''.join(names_list)\n","\n","print(names_str)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6fjRAQoul55Z","executionInfo":{"status":"ok","timestamp":1685339068265,"user_tz":-540,"elapsed":566,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"4cd31704-b660-4f71-8f99-c19f8c30de5d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(\\x28주\\x29동부|AKIS|CJ올리브네트웍스|DB아이앤씨|GS ITM|IBK시스템|KB데이터시스템|KT|KT DS|LG CNS|LG 유플러스|LS아이티씨|NDS|NH농협은행|SK|SK C&C|교보정보통신|농협정보시스템|동국시스템즈|동양네트웍스|동양시스템즈|두산디지털이노베이션|롯데백화점|롯데정보통신|메가존클라우드|메타넷대우정보|미라콤아이앤씨|베스핀글로벌|뷰웍스|비즈테크파트너스|삼성SDS|삼성전자|섹타나인|신세계아이앤씨|신한|신한데이타시스템|신한DS|신한금융그룹|신한카드|쌍용정보통신|쓱|아시아나IDT|우리에프아이에스|우리은행|유호스트|줌인터넷|카카오엔터프라이즈|케이뱅크|코오롱베니트|태광|티몬|티맥스소프트|티시스|포스코ICT|하나금융티아이|한국데이터베이스진흥원|한진정보통신|한화시스템/ICT|현대HDS|현대IT&E|현대모비스|현대아이파크몰|현대오토에버|현대오토에버|휴머스온)\n"]}]},{"cell_type":"code","source":["import re\n","from soynlp.normalizer import repeat_normalize\n","\n","pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣]+')\n","whitespace_symbol = re.compile(r'[\\t\\r\\n\\f\\v]+')"],"metadata":{"id":"AAehhYasvZYQ","executionInfo":{"status":"ok","timestamp":1685339069145,"user_tz":-540,"elapsed":882,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def text_preprocess(x):\n","    x = pattern.sub(' ', x)                     # 일반적으로 사용하는 특수문자, 영어, 한글제외 공백으로 치환\n","    x = whitespace_symbol.sub(' ', x)           # space(공백문자)를 제외한 whitespace 문자를 공백으로 치환\n","    x = re.sub(names_str, 'XX', x)\n","    x = x.strip()                               # 문자의 시작과 끝에서 공백제거\n","    x = repeat_normalize(x, num_repeats=2)      # 반목되는 문자의 축약 횟수 2개로 줄임\n","    return x"],"metadata":{"id":"apzArEgq8c2H","executionInfo":{"status":"ok","timestamp":1685339069146,"user_tz":-540,"elapsed":4,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["interview_data['Answer'][16]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"id":"etwe8rlzNac9","executionInfo":{"status":"ok","timestamp":1682926073891,"user_tz":-540,"elapsed":301,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"355a3677-c9cb-45e4-e5d2-6ce4664648ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"OOOOOO에서 주관하는 '제O기 사회리더 대학생 멘토링' 활동 때 팀워크를 발휘하여 공동의 목표 달성에 이바지한 경험이 있습니다. 저희는 고객과 헤어샵 사이 중개 플랫폼을 만들어보자는 목표를 설정하였습니다. 프로젝트에 고객수요조사, 플랫폼 설계 등 혼자 하기에는 무리가 있어서 팀을 구성하였고 저를 포함 5명이 팀을 이루게 되었습니다.\\n\\n저는 처음 본 조원들에게 효율적인 업무 분담하는 과정이 큰 난관이었습니다. 조원들 간의 장점을 최대한 끌어낼 방법을 찾기 위해 노력했습니다. 장시간 소통을 통해 문제를 해결하는 것이 우선이었습니다. 작품 회의를 하며 여러 업무를 분배하는 과정에서 개인마다 각자 잘할 수 있는 일이 있다는 사실을 인지할 수 있었습니다. 이를 바탕으로, 디자인 경력이 있는 조원에게는 디자인 업무, 평소에 책 읽기를 좋아하고 글 쓰는 재주가 있는 조원에게는 계획서 작성, 플랫폼 구현경험이 있는 조원에게는 App 구성 등 효율적인 업무분담을 할 수 있었습니다.\\n\\n1년이라는 장기프로젝트를 진행하면서 가장 힘들었던 점은 시간과 공간의 제약이었습니다. 각자의 전공공부와 프로젝트를 병행하는 시간적인 제약과 각각 다른 학교 출신으로 공간적인 제약을 조율하는 것은 정말 힘든 일이었습니다. 프로젝트를 자율적으로 진행하다 보니 진행 상황이 더뎌지는 상황을 확인할 수 있었습니다. 저희는 주 1회 정기적으로 모여 개개인의 업무 상황을 보고하고 서로의 업무진행에 대해 피드백하기로 했습니다. 피드백을 통해 구체적인 메시지를 전달하여 서로가 학습하고 성장할 수 있게 만들었습니다.\\n\\n팀워크의 가치를 현대모비스에서 실행해보고 싶습니다. 협동 부서의 역할을 이해하고 소통하여 팀원 간, 부서 간의 징검다리가 되겠습니다.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["interview_data.Question = interview_data.Question.apply(text_preprocess)\n","interview_data.Answer = interview_data.Answer.apply(text_preprocess)"],"metadata":{"id":"R7oudmYXLBCw","executionInfo":{"status":"ok","timestamp":1685339069455,"user_tz":-540,"elapsed":312,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["interview_data['Answer'][16]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"id":"18Lt2fHx_B07","executionInfo":{"status":"ok","timestamp":1682926075932,"user_tz":-540,"elapsed":4,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"bf00a94f-9ee0-465a-a9f6-4e72445e99ab"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"OO에서 주관하는 '제O기 사회리더 대학생 멘토링' 활동 때 팀워크를 발휘하여 공동의 목표 달성에 이바지한 경험이 있습니다. 저희는 고객과 헤어샵 사이 중개 플랫폼을 만들어보자는 목표를 설정하였습니다. 프로젝트에 고객수요조사, 플랫폼 설계 등 혼자 하기에는 무리가 있어서 팀을 구성하였고 저를 포함 5명이 팀을 이루게 되었습니다. 저는 처음 본 조원들에게 효율적인 업무 분담하는 과정이 큰 난관이었습니다. 조원들 간의 장점을 최대한 끌어낼 방법을 찾기 위해 노력했습니다. 장시간 소통을 통해 문제를 해결하는 것이 우선이었습니다. 작품 회의를 하며 여러 업무를 분배하는 과정에서 개인마다 각자 잘할 수 있는 일이 있다는 사실을 인지할 수 있었습니다. 이를 바탕으로, 디자인 경력이 있는 조원에게는 디자인 업무, 평소에 책 읽기를 좋아하고 글 쓰는 재주가 있는 조원에게는 계획서 작성, 플랫폼 구현경험이 있는 조원에게는 App 구성 등 효율적인 업무분담을 할 수 있었습니다. 1년이라는 장기프로젝트를 진행하면서 가장 힘들었던 점은 시간과 공간의 제약이었습니다. 각자의 전공공부와 프로젝트를 병행하는 시간적인 제약과 각각 다른 학교 출신으로 공간적인 제약을 조율하는 것은 정말 힘든 일이었습니다. 프로젝트를 자율적으로 진행하다 보니 진행 상황이 더뎌지는 상황을 확인할 수 있었습니다. 저희는 주 1회 정기적으로 모여 개개인의 업무 상황을 보고하고 서로의 업무진행에 대해 피드백하기로 했습니다. 피드백을 통해 구체적인 메시지를 전달하여 서로가 학습하고 성장할 수 있게 만들었습니다. 팀워크의 가치를 XX에서 실행해보고 싶습니다. 협동 부서의 역할을 이해하고 소통하여 팀원 간, 부서 간의 징검다리가 되겠습니다.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["# 데이터 구축"],"metadata":{"id":"mBxpknF4KeZP"}},{"cell_type":"markdown","source":["HuggingFace's BPEtokenizer"],"metadata":{"id":"L1XlwXGZK-Oh"}},{"cell_type":"code","source":["tokenize_data = interview_data.values.tolist()"],"metadata":{"id":"VgfESZjwPnjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tokenizers import Tokenizer\n","from tokenizers.models import BPE\n","from tokenizers.trainers import BpeTrainer\n","from tokenizers.pre_tokenizers import Whitespace\n","\n","tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n","trainer = BpeTrainer(\n","                vocab_size = 4000,          # vocab_size의 최댓값은 4375\n","                limit_alphabet = 10000,\n","                min_frequency = 3,\n","                special_tokens = [\"<unk>\", \"<s>\", \"</s>\", \"<pad>\", \"<mask>\"],\n","                continuing_subword_prefix = \"▁\"\n","                )\n","\n","tokenizer.pre_tokenizer = Whitespace()\n","\n","tokenizer.train_from_iterator(tokenize_data, trainer)"],"metadata":{"id":"2zsqQJ9hLAZJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.save('/content/drive/Othercomputers/내 컴퓨터/Interview_Writer/BPE_tokenizer.json')"],"metadata":{"id":"DZKUnZUuRzD-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**데이터셋 구축**"],"metadata":{"id":"nO_Pe3A4qz-y"}},{"cell_type":"code","source":["from transformers import PreTrainedTokenizerFast\n","\n","fast_tokenizer = PreTrainedTokenizerFast(tokenizer_file='/content/drive/Othercomputers/내 컴퓨터/Interview_Writer/BPE_tokenizer.json')"],"metadata":{"id":"5XuCgm93VPJn","executionInfo":{"status":"ok","timestamp":1685339070650,"user_tz":-540,"elapsed":1196,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from torch.utils.data import Dataset\n","\n","class DataSet(Dataset):\n","    def __init__(self, docs, tokenizer, max_len):\n","        super().__init__()\n","        self.docs = docs\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","        self.bos_id = tokenizer.convert_tokens_to_ids(\"<s>\")\n","        self.eos_id = tokenizer.convert_tokens_to_ids(\"</s>\")\n","        self.pad_id = tokenizer.convert_tokens_to_ids(\"<pad>\")\n","\n","    # padding 및 데이터 size 일치화 함수 (input_ids)\n","    def add_padding(self, inputs):\n","        if len(inputs) < self.max_len:\n","            pad = np.array([self.pad_id]*(self.max_len - len(inputs)))\n","            inputs = np.concatenate([inputs, pad])\n","        else:\n","            inputs = inputs[:self.max_len]\n","        return inputs\n","\n","    def __len__(self):  \n","        return len(self.docs)\n","\n","    def __getitem__(self, idx):\n","        Q = self.docs.Question[idx]\n","        A = self.docs.Answer[idx]\n","\n","        Q_token = [self.bos_id] + self.tokenizer.encode(Q) + [self.eos_id]\n","        A_token = self.tokenizer.encode(A) + [self.eos_id]\n","        \n","        # <s> Q </s> A </s> <pad>...\n","        input_ids = Q_token + A_token\n","        input_ids = self.add_padding(input_ids)\n","\n","        # attention_mask(어텐션마스크) = Q+A 길이 1 + 나머지(패딩) 0\n","        # token_type_ids(세그먼트 정보) = Q 0 + A 1 + 나머지 0\n","        if (self.max_len - len(Q_token+A_token)) > 0:\n","            attention_mask = [1]*(len(Q_token+A_token)) + [0]*(self.max_len - len(Q_token+A_token))\n","            token_type_ids = [0]*len(Q_token) + [1]*len(A_token) + [0]*(self.max_len - len(Q_token+A_token))\n","        else:\n","            attention_mask = [1]*(self.max_len)\n","            token_type = [0]*len(Q_token) + [1]*(self.max_len - len(A_token))\n","\n","        # A </s> <pad>...\n","        labels = self.tokenizer.encode(A) + [self.eos_id]\n","        labels = self.add_padding(labels)\n","\n","        return {'input_ids': np.array(input_ids, dtype=np.int_),\n","                'attention_mask': np.array(attention_mask, dtype=np.int_),\n","                'token_type_ids': np.array(token_type_ids, dtype=np.int_),\n","                'labels': np.array(labels, dtype=np.int_)}"],"metadata":{"id":"hqGgPWmBT5Eg","executionInfo":{"status":"ok","timestamp":1685339079368,"user_tz":-540,"elapsed":8720,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["Q_total = 0\n","A_total = 0\n","\n","for i in range(0, len(interview_data)):\n","\n","    question_length = len(interview_data.Question[i])\n","    answer_length = len(interview_data.Answer[i])\n","\n","    Q_total += question_length\n","    A_total += answer_length\n","\n","print(\"질문 평균길이 : \", (Q_total/len(interview_data)))\n","print(\"답 평균길이 : \", (A_total/len(interview_data)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDC2ZBgIdCdf","executionInfo":{"status":"ok","timestamp":1685339079368,"user_tz":-540,"elapsed":13,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"e7b158bf-37df-487c-8e75-7e31df0fa121"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["질문 평균길이 :  49.475\n","답 평균길이 :  651.2166666666667\n"]}]},{"cell_type":"code","source":["train_set = DataSet(interview_data, tokenizer=fast_tokenizer, max_len=1024)"],"metadata":{"id":"w7cpGjODcE-h","executionInfo":{"status":"ok","timestamp":1685339079849,"user_tz":-540,"elapsed":492,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["train_set[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4w1yk6HeeRlQ","executionInfo":{"status":"ok","timestamp":1685339079850,"user_tz":-540,"elapsed":8,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"be9a36fa-baed-4c01-bf17-c2917f55677d"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': array([   1, 3882, 1182, ...,    3,    3,    3]),\n"," 'attention_mask': array([1, 1, 1, ..., 0, 0, 0]),\n"," 'token_type_ids': array([0, 0, 0, ..., 0, 0, 0]),\n"," 'labels': array([2096,   18, 1929, ...,    3,    3,    3])}"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["**데이터로더 구축**"],"metadata":{"id":"F28NQnRg114n"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","train_dataloader = DataLoader(train_set, shuffle=False, batch_size=1)"],"metadata":{"id":"T1kGHKx9qpM5","executionInfo":{"status":"ok","timestamp":1685339080826,"user_tz":-540,"elapsed":2,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["next(iter(train_dataloader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yaC6W_QXr7kk","executionInfo":{"status":"ok","timestamp":1685339081130,"user_tz":-540,"elapsed":306,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"9ea008eb-5aa8-485e-c2b3-6f024d661649"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[   1, 3882, 1182,  ...,    3,    3,    3]]),\n"," 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]]),\n"," 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0]]),\n"," 'labels': tensor([[2096,   18, 1929,  ...,    3,    3,    3]])}"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["# 모델 정의 "],"metadata":{"id":"c1-xucLHbYxO"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.nn import CrossEntropyLoss\n","\n","from transformers.modeling_outputs import CausalLMOutputWithCrossAttentions\n","from typing import Optional, Union, Tuple"],"metadata":{"id":"McqcUNiwbsHS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**GPT에서 사용되는 Conv1D**"],"metadata":{"id":"DgyfLlIzJ5ph"}},{"cell_type":"code","source":["# weight가 transpose된 Linear layer\n","\n","class Conv1D(nn.Module):\n","    def __init__(self, nf, nx):     # nf : output / nx : input\n","        super().__init__()\n","        self.nf = nf\n","        self.weight = nn.Parameter(torch.empty(nx, nf))\n","        self.bias = nn.Parameter(torch.zeros(nf))\n","        nn.init.normal_(self.weight, std=0.02)\n","\n","    def forward(self, x):\n","        size_out = x.size()[:-1] + (self.nf,)\n","        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)     # Matrix multiplication\n","        x = x.view(size_out)\n","        return x"],"metadata":{"id":"txb1TxEvH4Qf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Decoder**"],"metadata":{"id":"hLnPwhorJiAx"}},{"cell_type":"code","source":["class Decoder_Block(nn.Module):\n","    def __init__(self, hidden_size, max_position_embeddings, layer_idx=None):\n","        super().__init__()\n","\n","        hidden_size = hidden_size\n","\n","        # Layer Normalization before attention\n","        self.ln_1 = nn.LayerNorm(hidden_size, eps=1e-5)\n","\n","        # Attention\n","        max_positions = max_position_embeddings\n","        \n","        self.register_buffer(\n","            \"bias\",\n","            torch.tril(torch.ones((max_positions, max_positions), dtype=torch.bool)).view(\n","                1, 1, max_positions, max_positions\n","            ),\n","        )\n","        self.embed_dim = hidden_size        \n","        self.num_heads = 8                 # attention heads\n","        self.head_dim = self.embed_dim // self.num_heads    # attention head size\n","        self.split_size = self.embed_dim\n","        self.layer_idx = layer_idx\n","\n","        self.c_attn = Conv1D(3 * self.embed_dim, self.embed_dim)\n","        self.c_proj = Conv1D(self.embed_dim, self.embed_dim)\n","\n","        self.attn_dropout = nn.Dropout(p = 0.1)\n","        self.resid_dropout = nn.Dropout(p = 0.1)\n","\n","        # Layer Normalization after attention\n","        self.ln_2 = nn.LayerNorm(hidden_size, eps=1e-5)\n","\n","        # MLP\n","        intermediate_size = 4 * hidden_size\n","        \n","        self.MLP_c_fc = Conv1D(intermediate_size, self.embed_dim)\n","        self.MLP_c_proj = Conv1D(self.embed_dim, intermediate_size)\n","        self.act = nn.GELU()\n","        self.MLP_drop = nn.Dropout(p = 0.1)\n","\n","    def _attn(self, query, key, value, attention_mask=None, head_mask=None):\n","        attn_weights = torch.matmul(query, key.transpose(-1, -2))       # query와 key의 전치행렬의 곱\n","        attn_weights = attn_weights / torch.full(\n","            [], value.size(-1) ** 0.5, dtype=attn_weights.dtype, device=attn_weights.device\n","        )\n","\n","        # Cross-Attention을 사용하지 않아 일반적인 Attention으로 casual_mask를 구현\n","        query_length, key_length = query.size(-2), key.size(-2)     # query와 key의 마지막 두번째 차원의 크기(seq_length)\n","        causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length]  # (batch_size, num_heads, query_length, key_length)\n","            \n","        mask_value = torch.finfo(attn_weights.dtype).min        # attn_weights의 데이터 타입에 맞는 최소값으로 설정\n","        mask_value = torch.tensor(mask_value, dtype=attn_weights.dtype).to(attn_weights.device)     # mask_value를 생성하고, attn_weights와 동일한 디바이스에 있는 데이터 타입으로 변환\n","\n","        attn_weights = torch.where(causal_mask, attn_weights, mask_value)   # attn_weights에서 쿼리 토큰에 대한 이전 토큰의 어텐션만을 유지하고, 나머지 위치에는 마스킹 값을 적용\n","\n","        attn_weights = nn.functional.softmax(attn_weights, dim=-1)      # Softmax\n","        attn_weights = attn_weights.type(value.dtype)                   # Value와 같은 타입으로 Downcast\n","        attn_weights = self.attn_dropout(attn_weights)                  # Dropout\n","\n","        attn_output = torch.matmul(attn_weights, value)                 # attn_weights와 value의 곱\n","        return attn_output, attn_weights\n","        \n","    # hidden_size를 attn_head_size와 num_head로 나누는 함수\n","    def _split_heads(self, tensor, num_heads, attn_head_size):\n","        new_shape = tensor.size()[:-1] + (num_heads, attn_head_size)\n","        tensor = tensor.view(new_shape)\n","        return tensor.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n","\n","    # attn_head_size와 num_head를 hidden_size로 병합하는 함수\n","    def _merge_heads(self, tensor, num_heads, attn_head_size):\n","        tensor = tensor.permute(0, 2, 1, 3).contiguous()\n","        new_shape = tensor.size()[:-2] + (num_heads * attn_head_size,)\n","        return tensor.view(new_shape)\n","\n","    def forward(\n","            self,\n","            hidden_states: Optional[Tuple[torch.FloatTensor]],\n","            attention_mask: Optional[torch.FloatTensor] = None,\n","            head_mask: Optional[torch.FloatTensor] = None\n","        ) -> Union[Tuple[torch.Tensor], Optional[Tuple[torch.Tensor, Tuple[torch.FloatTensor, ...]]]]:\n","\n","        \"\"\"Layer Normalization before attention\"\"\"\n","        residual = hidden_states\n","        hidden_states = self.ln_1(hidden_states)\n","\n","        \"\"\"Attention\"\"\"\n","        query, key, value = self.c_attn(hidden_states).split(self.split_size, dim=2)    # Conv1D + split\n","\n","        query = self._split_heads(query, self.num_heads, self.head_dim)     # split_head\n","        key = self._split_heads(key, self.num_heads, self.head_dim)\n","        value = self._split_heads(value, self.num_heads, self.head_dim)\n","\n","        attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)\n","\n","        attn_output = self._merge_heads(attn_output, self.num_heads, self.head_dim)     # merge\n","        attn_output = self.c_proj(attn_output)          # Conv1D\n","        attn_output = self.resid_dropout(attn_output)   # Dropout\n","        present=None\n","\n","        attn_outputs = (attn_output, present)\n","\n","        \"\"\"Layer Normalization after attention + Adding Tensor\"\"\"\n","        attn_output = attn_outputs[0]       # output_attn: a, present, (attentions)\n","        hidden_states = attn_output + residual      # residual connection\n","\n","        residual = hidden_states\n","        hidden_states = self.ln_2(hidden_states)\n","\n","        \"\"\"MLP\"\"\"\n","        hidden_states = self.MLP_c_fc(hidden_states)\n","        hidden_states = self.act(hidden_states)\n","        hidden_states = self.MLP_c_proj(hidden_states)\n","        hidden_states = self.MLP_drop(hidden_states)\n","\n","        \"\"\"Adding Tensor\"\"\"\n","        hidden_states = hidden_states + residual    # residual connection\n","        outputs = (hidden_states,) + attn_outputs[1:]\n","\n","        return outputs      # hidden_states, present, (attentions, cross_attentions)"],"metadata":{"id":"K08gEkVbrrJI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**전체 모델 구성**"],"metadata":{"id":"E4rfDoPHJdvd"}},{"cell_type":"code","source":["class Decoder_Model(nn.Module):\n","    def __init__(self, vocab_size, hidden_size=256, max_position_embeddings=1024):\n","        super().__init__()\n","\n","        hidden_size = hidden_size\n","        self.embed_dim = hidden_size\n","\n","        self.wte = nn.Embedding(vocab_size, self.embed_dim)     # vocab_size * hidden_size\n","        self.wpe = nn.Embedding(max_position_embeddings, self.embed_dim)    # max_position_embeddings * hidden_size\n","\n","        self.drop = nn.Dropout(p = 0.1)\n","        self.h = nn.ModuleList([Decoder_Block(hidden_size, max_position_embeddings, layer_idx=i) for i in range(4)])    # Attention+MLP를 4층\n","        self.ln_f = nn.LayerNorm(self.embed_dim, eps=1e-5)\n","        self.lm_head = nn.Linear(self.embed_dim, vocab_size, bias=False)\n","\n","    def forward(\n","        self,\n","        input_ids: Optional[torch.LongTensor] = None,\n","        attention_mask: Optional[torch.FloatTensor] = None,\n","        token_type_ids: Optional[torch.LongTensor] = None,\n","        labels: Optional[torch.LongTensor] = None\n","        ) -> Union[Tuple, CausalLMOutputWithCrossAttentions]:\n","        \n","        \"\"\"Embedding Layer\"\"\"\n","        # Word Embedding 입력 = input_ids\n","        input_shape = input_ids.size()\n","        input_ids = input_ids.view(-1, input_shape[-1])\n","        batch_size = input_ids.shape[0]\n","\n","        # Token Type Embedding 입력 = token_type_ids\n","        token_type_ids = token_type_ids.view(-1, input_shape[-1])\n","\n","        # Position Embedding 입력 = position_ids (create)\n","        past_length = 0     # past_key_values is None\n","        past_key_values = tuple([None] * len(self.h))\n","        position_ids = torch.arange(past_length, input_shape[-1] + past_length, dtype=torch.long, device=device)\n","        position_ids = position_ids.unsqueeze(0).view(-1, input_shape[-1])\n","\n","        # 2D attention으로 3D attention을 만듦([batch_size, num_heads, from_seq_length, to_seq_length])\n","        attention_mask = attention_mask.view(batch_size, -1)\n","        attention_mask = attention_mask[:, None, None, :]\n","        attention_mask = attention_mask.to(dtype=self.dtype)    # fp16 compatibility (GPU 16비트 부종소수점 호환성)\n","        attention_mask = (1.0 - attention_mask) * torch.finfo(self.dtype).min\n","        \n","        # Word Embedding\n","        inputs_embeds = self.wte(input_ids)\n","        \n","        # Position Embedding\n","        position_embeds = self.wpe(position_ids)\n","        hidden_states = inputs_embeds + position_embeds\n","        \n","        # Token Type Embedding\n","        token_type_embeds = self.wte(token_type_ids)\n","        hidden_states = hidden_states + token_type_embeds\n","\n","        # Dropout\n","        hidden_states = self.drop(hidden_states)\n","        output_shape = input_shape + (hidden_states.size(-1),)\n","\n","        \"\"\"ModuleList (attention, multi-layer perceptron)\"\"\"\n","        for i, (block, layer_past) in enumerate(zip(self.h, past_key_values)): \n","            outputs = block(\n","                hidden_states,\n","                attention_mask=attention_mask\n","            )\n","            hidden_states = outputs[0]\n","\n","        \"\"\"LayerNorm\"\"\"\n","        hidden_states = self.ln_f(hidden_states)\n","        hidden_states = hidden_states.view(output_shape)\n","\n","        \"\"\"Linear layer\"\"\"\n","        lm_logits = self.lm_head(hidden_states)\n","\n","        \"\"\"loss값 계산\"\"\"\n","        loss = None\n","        if labels is not None:\n","            labels = labels.to(lm_logits.device)\n","\n","            # 마지막 차원의 마지막 원소를 제외한 부분을 선택 (다음 토큰을 예측)\n","            shift_logits = lm_logits[..., :-1, :].contiguous()\n","            # 첫 번째 원소를 제외한 부분을 선택 (실제 정답 토큰)\n","            shift_labels = labels[..., 1:].contiguous()\n"," \n","            # 2D 형태로 변환 (Flatten) 후 loss 함수에 적용\n","            loss_fct = CrossEntropyLoss()\n","            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n","\n","        return CausalLMOutputWithCrossAttentions(\n","            loss = loss,\n","            logits = lm_logits\n","        )"],"metadata":{"id":"2uPdSoYabbEe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 모델 학습\n","\n","**모델 파라미터 설정**"],"metadata":{"id":"JKUnGLzF0eFK"}},{"cell_type":"code","source":["import torch\n","\n","model = Decoder_Model(vocab_size=fast_tokenizer.vocab_size, hidden_size=256, max_position_embeddings=1024)\n","# GPU 가속을 사용할 수 있으면 device를 cuda로 설정하고, 아니면 cpu로 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","epoch = 10\n","learning_rate = 1e-5\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"],"metadata":{"id":"evu48o020gAc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0Q76Ym730Z8","executionInfo":{"status":"ok","timestamp":1685084668696,"user_tz":-540,"elapsed":4,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"84f52fb3-e18d-44fa-bdeb-4b262338ebe4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Decoder_Model(\n","  (wte): Embedding(4000, 256)\n","  (wpe): Embedding(1024, 256)\n","  (drop): Dropout(p=0.1, inplace=False)\n","  (h): ModuleList(\n","    (0-3): 4 x Decoder_Block(\n","      (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (c_attn): Conv1D()\n","      (c_proj): Conv1D()\n","      (attn_dropout): Dropout(p=0.1, inplace=False)\n","      (resid_dropout): Dropout(p=0.1, inplace=False)\n","      (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","      (MLP_c_fc): Conv1D()\n","      (MLP_c_proj): Conv1D()\n","      (act): GELU(approximate='none')\n","      (MLP_drop): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","  (lm_head): Linear(in_features=256, out_features=4000, bias=False)\n",")"]},"metadata":{},"execution_count":18}]}]}